---
layout: post
title:  "调试处理（Tuning process）-吴恩达 深度学习 course2 3.1~3.3笔记"
date:   2018-05-08 10:31:30
categories: DeepLearning
tags: DeepLearning 吴恩达
mathjax: true
---
* content
{:toc}
对于超参数而言，如何找到一套好的设定呢？本课中，我将和你分享一些指导原则，一些关于如何系统地组织超参调试过程的技巧。
<!--more-->

对于超参数而言，如何找到一套好的设定呢？本课中，我将和你分享一些指导原则，一些关于如何系统地组织超参调试过程的技巧。
# 调试处理（Tuning process）
## 参数的重要程度排序

关于训练深度最难的事情之一是你要处理的参数的数量，从学习速率 α 到Momentum（动量梯度下降法）的参数 β 。如果使用Momentum或Adam优化算法的参数 β1，β2和 ε，也许你还得选择层数，也许你还得选择不同层中隐藏单元的数量，也许你还想使用学习率衰减。所以，你使用的不是单一的学习率α。接着，当然你可能还需要选择mini-batch的大小。

结果证实一些超参数比其它的更为重要。

###  最重要



- 学习速率 α；

###   其次重要


- β：动量衰减参数，常设置为 0.9；

- #hidden units：各隐藏层神经元个数；

- mini-batch 的大小；

### 重要性排第三位

- β1，β2，ϵ：Adam 优化算法的超参数，常设为 0.9、0.999、10−8；

- #layers：神经网络层数;

- decay_rate：学习衰减率；

       ![hyperparameters](http://p5ocy6pck.bkt.clouddn.com/hyperparameters.png)

希望你粗略了解到哪些超参数较为重要，α无疑是最重要的，接下来是我用橙色圈住的那些，然后是我用紫色圈住的那些，但这不是严格且快速的标准，我认为，其它深度学习的研究者可能会很不同意我的观点或有着不同的直觉。

## 调参技巧

### 随机选择点

![try random values:don't use a grid](http://p5ocy6pck.bkt.clouddn.com/try%20random%20values.png)

现在，如果你尝试调整一些超参数，该如何选择调试值呢？在早一代的机器学习算法中，如果你有两个超参数，这里我会称之为超参1，超参2，常见的做法是在网格中取样点，像这样，然后系统的研究这些数值。这里我放置的是5×5的网格，实践证明，网格可以是5×5，也可多可少，但对于这个例子，你可以尝试这所有的25个点，然后选择哪个参数效果最好。**当参数的数量相对较少时，这个方法很实用。**

**在深度学习领域，我推荐你采用随机选择点**，你可以选择同等数量的点，25个点，接着，用这些随机取的点试验超参数的效果。之所以这么做是因为，对于你要解决的问题而言，你很难提前知道哪个超参数最重要，正如你之前看到的，一些超参数的确要比其它的更重要。

举个例子，假设超参数1是α（学习速率），取一个极端的例子，假设超参数2是Adam算法中，分母中的ε。在这种情况下，α的取值很重要，而ε取值则无关紧要。如果你在网格中取点，接着，你试验了αα的5个取值，那你会发现，无论ε取何值，结果基本上都是一样的。所以，你知道共有25种模型，但进行试验的α值只有5个，我认为这是很重要的。

对比而言，如果你随机取值，你会试验25个独立的，似乎你更有可能发现效果做好的那个。

实践中，哪个是最重要的超参数，对于你的具体应用而言，随机取值而不是网格取值表明，你探究了更多重要超参数的潜在值，无论结果是什么。

### 由粗糙到精细的策略

当你给超参数取值时，另一个惯例是采用 **由粗糙到精细的策略 :聚焦效果不错的点组成的小区域，在其中更密集地取值，以此类推**

![coarse to fine](http://p5ocy6pck.bkt.clouddn.com/coarse%20to%20fine.png)

比如在二维的那个例子中，你进行了取值，也许你会发现效果最好的某个点，也许这个点周围的其他一些点效果也很好，那在接下来要做的是放大这块小区域（小蓝色方框内），然后在其中更密集得取值或随机取值，聚集更多的资源，在这个蓝色的方格中搜索，如果你怀疑这些超参数在这个区域的最优结果，那在整个的方格中进行粗略搜索后，你会知道接下来应该聚焦到更小的方格中。在更小的方格中，你可以更密集得取点。所以这种从粗到细的搜索也经常使用。

通过试验超参数的不同取值，你可以选择对训练集目标而言的最优值，或对于开发集而言的最优值，或在超参搜索过程中你最想优化的东西。

我希望，这能给你提供一种方法去系统地组织超参数搜索过程。另一个关键点是随机取值和精确搜索，考虑使用由粗糙到精细的搜索过程。

# 3.2为超参数选择合适的范围（Using an appropriate scale to pick hyperparameters）

在上一课中，你已经看到了在超参数范围中，随机取值可以提升你的搜索效率。但随机取值并不是在有效范围内的随机均匀取值，而是选择合适的标尺，用于探究这些超参数。

- 对于学习率 α，用对数标尺而非线性轴的方式搜索超参数更加合理：0.0001、0.001、0.01、0.1 等，然后在这些刻度之间再随机均匀取值；
- 对于 β，取 0.9 就相当于在 10 个值中计算平均值，而取 0.999 就相当于在 1000 个值中计算平均值。可以考虑给 1-β 取值，这样就和取学习率类似了。

上述操作的原因是当 β 接近 1 时，即使 β 只有微小的改变，所得结果的灵敏度会有较大的变化。例如，β 从 0.9 增加到 0.9005 对结果（1/(1-β)）几乎没有影响，而 β 从 0.999 到 0.9995 对结果的影响巨大（从 1000 个值中计算平均值变为 2000 个值中计算平均值）。

# 3.3 超参数训练的实践：Pandas VS Caviar（Hyperparameters tuning in practice: Pandas vs. Caviar）

- 深度学习如今已经应用到许多不同的领域。不同的应用出现相互交融的现象，某个应用领域的超参数设定有可能通用于另一领域。不同应用领域的人也应该更多地阅读其他研究领域的 paper，跨领域地寻找灵感；

- 考虑到数据的变化或者服务器的变更等因素，建议每隔几个月至少一次，重新测试或评估超参数，来获得实时的最佳模型；

- 根据你所拥有的计算资源来决定你训练模型的方式：
1. Panda（熊猫方式）：在在线广告设置或者在计算机视觉应用领域有大量的数据，但受计算能力所限，同时试验大量模型比较困难。可以采用这种方式：试验一个或一小批模型，初始化，试着让其工作运转，观察它的表现，不断调整参数；
1.  Caviar（鱼子酱方式）：拥有足够的计算机去平行试验很多模型，尝试很多不同的超参数，选取效果最好的模型；

![hpyerparameters tuning in practice](http://p5ocy6pck.bkt.clouddn.com/Hyperparameters%20tuning%20in%20practice.png)
