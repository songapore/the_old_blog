---
layout: post
title:  "无人驾驶第一课-Lesson 1：无人驾驶概览"
date:   2018-07-11 19:50:15
categories: self-driving
tags: 无人驾驶
      Apollo
---

* content
{:toc}

从 Apollo 起步-Lesson 1：无人驾驶概览
<!--more-->

# 无人驾驶概览
Udacity无人驾驶项目负责人David Silver 表示： “在全球无人驾驶技术人才奇缺的宏观现实下，如果你对无人驾驶汽车感兴趣，或者有志于从事无人驾驶开发的工作，现在就是最好的时机
## 你将学到什么

 Apollo 无人驾驶开源平台的主要部分

 - high-definition maps 高精度地图

 无人驾驶车的核心模块——高精度地图，几乎支持着软件栈的所有其他模块，包括定位、感知、预测和规划
 - localization 定位

 在定位课程中，将讨论汽车如何确定它所处的位置。这比预想得更难！汽车利用激光和雷达数据，将这些传感器感知内容与高分辨率地图进行对比，这种对比使汽车能够以个位数厘米级精度进行自定位
 - perception 感知

 在感知课程中，将了解无人驾驶车如何感知这个世界。深度学习是一个重要且强有力的感知工具，卷积神经网络构成深度学习分支，对感知任务至关重要。如分类、检测和分割，这些方法适用于几种不同无人驾驶车传感器的数据来源，包括摄像头、雷达和激光雷达
 - prediction 预测

 我们将概述几种不同的方式，用于预测其他车辆或行人可能如何移动。一种方法称为递归神经网络。可对其他物体随时间的运动进行跟踪，并使用该时间序列数据预测未来
 - planning 规划

 规划课程将涵盖如何将预测与路线相结合以生成车辆轨迹，规划是构建无人驾驶车最困难的部分之一
 - control 控制

 控制课程展示了如何使用转向、油门和制动来执行规划轨迹。我们将阐释几种不同类型的控制器，类型从简单到愈加复杂，而性能却从弱到强

 希望：在完成这门课时，你将了解无人驾驶车的基本工作原理。我希望你开始这段学习之旅时，像我第一次开始学习无人驾驶车时那样激动

 ### Apollo核心模块
 在课程开始之前, 你可以先阅读Github中以下模块的Readme, 来对无人驾驶技术的架构有一个总体的了解~
 - [定位](https://github.com/ApolloAuto/apollo/blob/master/modules/localization/README_cn.md)
 - [感知](https://github.com/ApolloAuto/apollo/blob/master/modules/perception/README_cn.md)
 - [预测](https://github.com/ApolloAuto/apollo/blob/master/modules/prediction/README_cn.md)
 - [路由](https://github.com/ApolloAuto/apollo/blob/master/modules/routing/README_cn.md)
 - [规划](https://github.com/ApolloAuto/apollo/blob/master/modules/planning/README_cn.md)
 - [控制](https://github.com/ApolloAuto/apollo/blob/master/modules/control/README_cn.md)

## 为什么我们需要无人驾驶车？
最重要的原因是安全

![比较](http://p5ocy6pck.bkt.clouddn.com/compare%20human%20and%20self%20driving.png)

### 无人车等级划分
汽车工程师已建立并确定了 6 个等级的无人驾驶车
![自动驾驶等级划分]](http://p5ocy6pck.bkt.clouddn.com/%E8%87%AA%E5%8A%A8%E9%A9%BE%E9%A9%B6%E7%9A%84%E5%88%86%E7%BA%A7%E6%AF%94%E8%BE%83.jpg)

- 0 级为基本等级，驾驶员是系统的唯一决策者
- 1 级为驾驶员辅助，车辆为驾驶员提供转向或加速支持如巡航控制
- 2 级为部分自动化，车辆自动控制几项功能如自动巡航控制和车道保持
- 3 级为有条件的自动化，车辆自主驾驶
- 4 级为高度自动化，车辆控制、驾驶方面不期望驾驶员的介入
- 5 级为最高级别，完全自动化，应与人类驾驶员的水平一样高或比其更高

![sae autonomy levels](http://p5ocy6pck.bkt.clouddn.com/SAE%20autonomy%20levels.png)

## How self-driving cars work
无人驾驶车包括五个核心部件
![](http://p5ocy6pck.bkt.clouddn.com/how%20a%20self-driving%20car%20works.png)

- **计算机视觉** 就是我们通过摄像头图像弄清楚我们周围的世界是怎样的
- **传感器融合** 是我们合并来自其他传感器的数据， 如激光和雷达，从而更加深入地了解我们周围的环境
- 只要我们对周围的世界有了深刻的理解，就可以使用 **定位** 来精确地确定我们在那个世界所处的位置
- 弄清楚where we are in the world and what the world looks like，就可以使用 **路径规划** 来绘制路线
- **控制** 就是我们为了让汽车沿着我们在路径规划期间建立的轨道，如何转动方向盘并打开油门 然后踩刹车

## Apollo 技术框架由四个层面组成
参考车辆平台、参考硬件平台、开源软件平台和云服务平台
## 参考车辆与硬件平台

如果我们想要打造一辆无人驾驶车。首先要开发一款可通过电子控制的基础车辆，而不仅仅是通过实体方向盘、油门踏板和刹车踏板来控制，这种类型的车辆具有特殊的名称：**线控驾驶车辆**

Apollo 无人驾驶车有几个不同的传感器。
- 控制器区域网络（或 CAN），是车辆的内部通信网络，计算机系统通过 CAN 卡连接汽车内部网络，发送加速、制动和转向信号。
- 全球定位系统（或 GPS），通过绕地卫星接收信号，这些信号可帮助我们确定所处位置。
- 惯性测量装置（或 IMU），测量车辆的运动和位置，是通过跟踪位置、速度、加速度和其他因素。
- 激光雷达 (LiDAR) 由一组脉冲激光器组成Apollo 使用的激光雷达可 360 度扫描车辆周围，这些激光束的反射形成了软件可用于了解环境的点云
- 摄像头捕获图像数据，我们可以使用计算机视觉来提取这些图像的内容并了解周围的环境。例如 因为摄像头可以感知颜色，我们用它们来检测和了解交通灯
- 雷达也用于检测障碍物，雷达分辨率低，难以分辨雷达检测到了哪种障碍物，但雷达的优势在于经济实惠，适用于各种天气和照明条件，雷达特别擅长测量其他车辆的速度。

下图说明如何将主要硬件组件安装到车辆上,包括摄像头、雷达、激光雷达、GPS-IMU 和 IPC
![](http://p5ocy6pck.bkt.clouddn.com/applo%20hardware.png)

## 开源软件栈
软件层分为三个子层:**实时操作系统(real-time operating system(ROTS))**、**运行时框架(Runtime Framework)** 和 **应用程序模块层(a layer of application modules)**

**实时操作系统（或 RTOS）**可确保在给定时间内完成特定任务。“实时”是指无人驾驶车的操作系统能够及时进行计算、分析并执行相应的操作。实时性能是确保系统稳定性和驾驶安全性的重要要求。

Apollo RTOS 是 Ubuntu Linux 操作系统与 Apollo 内核相互结合的成果。Ubuntu 是业内顶级 Linux 发行版之一，也是最流行的云操作系统，然而 原始 Ubuntu 系统并非实时操作系统，通过加入 Apollo 设计的内核 我们可以使其成为一个 RTOS。

**运行时框架** 是 Apollo 的操作环境它是 ROS（机器人操作系统）的定制版，ROS 实际上是一个在 Apollo RTOS 上运行的软件框架。ROS 在机器人行业有着悠久的历史，目前有 3,000 多个基础库支持应用程序的快速开发，ROS 根据功能将自治系统划分为多个模块，每个模块负责接收、处理和发布自己的消息。由于这些模块相互独立 只能通过运行时框架进行通信，因此调整任何单一模块都很容易。ROS 是应用最广泛的机器人框架，因此它所包含的模块涉及许多最新的研究突破，所有这些功能使 ROS 成为理想的 Apollo 开发与集成框架。

**为使 ROS 适应无人驾驶车，Apollo 团队改进了共享内存的功能和性能、去中心化和数据兼容性**

- **共享内存**降低了需要访问不同模块时的数据复制需求。

对于一对多传输方案，共享内存支持“一次写入 多次读取”模式。例如 如果你只收到一次点云 你可以同时运行障碍物检测、定位和 GUI 工具。这可以加快通信速度

- **去中心化** 解决了单点故障问题

现成的 ROS 由许多节点组成,每个节点都有对应的功能。例如 一个节点可能负责收集摄像头图像，另一个节点可能负责规划轨迹，而第三个节点可能负责将控制命令发送到 CAN 总线上的车辆，但是所有这些节点都需要由单个 ROS 主节点来控制。如果这个主节点发生故障，整个系统都会失效。

为了避免这个问题，Apollo 将所有节点放在一个公共域中，域中的每个节点都有关于域中其他节点的信息，通过这种去中心化方案，公共域取代了原来的 ROS 主节点，因此消除了单点故障风险。

- 对于无人驾驶车来说 由于项目本身的规模很大，**数据兼容性** 至关重要

不同的 ROS 节点通过,名为 ROS 消息的接口语言相互通信。ROS 消息需要使用通用接口语言，使每个节点都可以解读来自其他节点的消息数据。如果消息文件的格式，与节点所期望的格式稍有不同，通信会失败，这可能会导致严重的兼容性问题。例如 当一个接口升级时，数据不兼容通常会导致系统故障。此外 必须一次又一次地转换之前所记录的测试数据， 以适应新的消息格式。

**为了解决这个问题，Apollo 团队使用另一种名为 protobuf 的接口语言，来替代原生 ROS 消息。Protobuf 是一种结构化数据序列化方法**. 这对开发用于通过电线彼此通信，或用于存储数据的程序非常有用。你可以将新字段添加到消息格式中 而不会破坏后向兼容性，新的二进制文件可以在解析过程中接受旧的消息格式。向 ROS 添加 protobuf 格式有助于 Apollo 的长期发展。

- **应用程序模块**

Apollo 的软件平台具有各种模块，这些模块包括 MAP 引擎、定位、感知、规划、控制、端到端驾驶以及人机接口（或 HMI）。每个模块都有自己的算法库，模块之间的关系非常复杂。后续将在整个课程中对这些模块及其关联方式进行研究

## 云服务
**Apollo 云服务包含高精度地图(HD Maps)、仿真环境(Simulation)、数据平台(Data Platform)、安全(Security)、软件升级(OTA)以及被称为 DuerOS 的智能语音系统**

在这里 我们将重点介绍仿真和数据平台。
- **仿真环境平台**是 Apollo 开放软件栈的重要工具

该平台允许每个人出于自身需要 来构建仿真环境。该平台还聚合了大量驾驶数据，使开发人员能够检验和验证无人驾驶软件系统。仿真环境使 Apollo 车辆不仅可以查看环境，还可以了解道路情况和场景。

仿真环境平台具有许多功能。首先，仿真环境平台允许开发人员配置不同的驾驶场景，比如障碍物，路线和交通灯状态。执行模式为开发人员提供了一个在多个场景中运转的完整设置。在执行模式中 ，开发人员可以在 Apollo 环境中上传和验证模块。当前的自动评分系统，从几个指标对场景进行评估。其中包括：碰撞检测、交通灯识别、速度限制、障碍物检测和路线逻辑。最后，三维可视化描述了实时路况。在显示无人驾驶车状态的同时，使模块输出可视化。

- 数据对无人驾驶车来说很重要。无人驾驶数据可能来自模拟场景或道路测试，Apollo 为这些类别提供了各种各样的数据。

仿真场景数据有两个不同的来源：记录场景和虚拟场景。我们可以使用记录的场景，来重放我们在实际道路测试中已经观察到的传感器数据，我们可以借助虚拟场景 使用虚拟编辑器创建新的驾驶场景，这有助于快速检验与验证算法。为了训练像深度学习网络那样的机器学习模型，我们需要带标签的注释数据，其中包括交通信号灯数据，带边界框的障碍物数据，以及语义分割数据。

此外 Apollo 已向公众发布了 ApolloScape 数据集。ApolloScape 涵盖了各种复杂路况，ApolloScape 在单个图像中列入并注释了，多达 162 辆车或 80 名行人。同时 开放数据集使用语义分割对图像进行逐像素标记，这使得 ApolloScape 成为世界上最为复杂又最精确的无人驾驶数据集。
